<!DOCTYPE html>

<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Sebastian | Portfolio</title>

    <link rel="stylesheet" href="style/index.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
    <link rel="icon" type="image/png" href="res/favicon.png">

    <script src="scripts/index.js"></script>

</head>

<body>

    <div class="sidepanel">
        <img src="res/seb.jpeg" alt="Image of Sebastian Thiem" class="pfp">

        <div class="namecard">
            <h2>Sebastian Thiem</h2>
            <p style="color: #e1e1e1;">Computer Engineer</p>
        </div>

        <div class="tableofcontents">
            <a class="button" href="#home">Home</a>
            <a class="button" href="#aboutIndex">About</a>
            <a class="button" href="#skillsIndex">Skills</a>
            <a class="button" href="#educationIndex">Education</a>
            <a class="button" href="#employmentIndex">Employment</a>
            <a class="button" href="#projectsIndex">Projects</a>
            <a class="button" href="#publicationsIndex">Publications</a>
        </div>

        <div class="contactsbox">
            <a href="https://github.com/SeaBass917" class="githublink" target="_blank"> 
                <i class="fab fa-github fa-2x text-secondary"></i>
                <p>Github</p>
            </a>
            <a href="https://www.linkedin.com/in/sebastian-thiem-4b25b1159/" class="linkedinlink" target="_blank">
                <i class="fab fa-linkedin-in fa-2x text-secondary"></i>
                <p>LinkedIn</p>
            </a>
        </div>

        <footer>
            &#169; Copyright 2020 Sebastian Thiem
            <br>
            All Rights Reserved.
        </footer>
    </div>

    <div id="main">
        <div id="home">
            <img src="res/green-hk-2-inv.jpg" alt="" style="width: 100%;">
            <!-- <img src="res/pond-sc.jpg" alt="" style="width: 100%;"> -->
        </div>
        <div id="aboutIndex" class="index">
            <div id="about">
                <img src="res/seb-coin-4.jpg" alt="Sebastian presenting at COIN">
                <div id="aboutTextContainer">
                    <div>
                        <!-- <h1>About Me </h1> -->
                        <p>
                            My name is Sebastian. I am an up and coming engineer with a solid foundation 
                            in software development and a passion for pushing technology to the next level.
                        </p>
                    </div>
                    <ul>
                        <li><p>Quick study</p></li>
                        <li><p>Unbreakable work ethic</p></li>
                        <li><p>Attention to detail</p></li>
                        <li><p>Never afraid to ask questions</p></li>
                        <li><p>Broad skillset</p></li>
                        <!-- <li>A good sense of the things I know and the things I know I don't know</li> -->
                    </ul>
                </div>
            </div>
        </div>
        <div id="skillsIndex" class="index">
            <div id="skills">
                <!-- <h1>Skills</h1> -->
                <div>
                    <!-- <h3>High Level</h3> -->
                    <div class="tagbox tag0">
                        <p>Research</p>
                        <p>High Performance Computing</p>
                        <p>DSP</p>
                        <p>Web/App Development</p>
                        <p>FPGA</p>
                    </div>
                </div>

                <div>
                    <!-- <h3>Languages</h3> -->
                    <div class="tagbox tag1">
                        <p>C++</p>
                        <p>Python</p>
                        <p>C</p>
                        <p>Bash</p>
                        <p>JavaScript</p>
                        <p>C#</p>
                        <p>Scala</p>
                        <p>Verilog</p>
                        <p>Dart</p>
                        <p>MATLAB</p>
                        <p>Assembly</p>
                    </div>
                </div>

                <div>
                    <!-- <h3>Environments</h3> -->
                    <div class="tagbox tag2">
                        <p>Linux</p>
                        <p>CUDA</p>
                        <p>Arduino</p>
                        <p>Raspberry Pi</p>
                        <p>Node.JS</p>
                        <p>MPI</p>
                        <p>OpenMP</p>
                        <p>Docker</p>
                        <p>PyQT</p> 
                    </div>
                </div>
            </div>
        </div>
        <div id="educationIndex" class="index">
            <div id="education">
                <div id="educationContainer">
                    <h1>Education</h1>
                    <table>
                        <tr>
                            <td>Present</td> <td style="font-weight: bold;">Computer Engineering (M.S)</td> <td>3.9&nbsp;GPA</td>
                        </tr>
                        <tr>
                            <td></td>        <td style="font-weight: bold;">University of Arizona</td>      <td></td>
                        </tr>
                        <tr>
                            <td></td>        <td></td>      <td></td>
                        </tr>
                        <tr>
                            <td>2019</td>    <td style="font-weight: bold;">Computer Engineering (B.S)</td>      <td>3.8&nbsp;GPA</td>
                        </tr>
                        <tr>
                            <td></td>        <td style="font-weight: bold;">University of Arizona</td>      <td></td>
                        </tr>
                        <tr>
                            <td></td>        <td>Magna Cum Laude,&nbsp;Tau Beta Pi</td>      <td></td>
                        </tr>
                    </table>
                </div>
                <img src="res/ece-2.jpg" alt="UofA ECE Building">
            </div>
        </div>
        <div id="employmentIndex" class="index">
            <div id="employment">
                <div>
                    <h1>Employment</h1>
                    <p id="jobtitle">Research Assistant -- University of Arizona</p>
                    <p id="jobtimeline">June 2019 - June 2020</p>
                    <p id="jobdescription">
                        The lab’s goal was to design and implement algorithms for automatically constructing human readable explanations to 
                        science exam questions. My work involved designing an interactive web-tool for annotating a large dataset of explanatory 
                        patterns based on a corpus of full explanations to science questions. Annotators then used the tool, and from the dataset they 
                        generated, we created a model that would produce human readable explanations.
                    </p>
                </div>
                <img src="res/spock-lab.jpg" alt="Spock">
    
            </div>
        </div>
        <div id="projectsIndex" class="index">
            <div id="projects">
                <h1>Projects</h1>
                <div class="cardbox">
                    <div id="project7" class="card">
                        <div class="cardImgParent">
                            <img src="res/wordseg.png" alt="Segmented Words">
                        </div>
                        <div>
                            <h2>GLOCR</h2>
                            <h4>2020 (In Progess)</h4>
                            <div class="tagbox tag4">
                                <p>Computer Vision</p>
                                <p>OCR</p>
                                <p>Image Analysis</p>
                                <p>C++17/20</p>
                            </div>
                            <a id="project7Btn" class="button">Click to expand...</a>
                        </div>
                    </div>
                    <div id="project6" class="card">
                        <div class="cardImgParent">
                            <img src="res/patGraph.png" alt="Graph Pattern">
                        </div>
                        <div>
                            <h2>Syncronicity</h2>
                            <h4>2019-2020</h4>
                            <div class="tagbox tag4">
                                <p>AI</p>
                                <p>NLP</p>
                                <p>UI Design</p>
                                <p>Big Data</p>
                                <p>JS</p>
                                <p>Full-Stack</p>
                            </div>
                            <a id="project6Btn" class="button">Click to expand...</a>
                        </div>
                    </div>
                    <div id="project5" class="card">
                        <div class="cardImgParent">
                            <img src="res/pacman.png" alt="Pacman">
                        </div>
                        <div>
                            <h2>Pacman AI (Berkeley)</h2>
                            <h4>2020</h4>
                            <div class="tagbox tag4">
                                <p>AI</p>
                                <p>Search Algorithms</p>
                                <p>Python</p>
                                <p>Q Learning</p>
                            </div>
                            <a id="project5Btn" class="button">Click to expand...</a>
                        </div>
                    </div>
                    <div id="project4" class="card">
                        <div class="cardImgParent">
                            <img src="res/sysFlow-uasd.png" alt="Flow Diagram">
                        </div>  
                        <div>
                            <h2>GPU Powered Demod</h2>
                            <h4>2018-2019</h4>
                            <div class="tagbox tag4">
                                <p>DSP</p>
                                <p>Industry Sponsored</p>
                                <p>CUDA/C++</p>
                                <p>Team Project</p>
                            </div>
                            <a id="project4Btn" class="button">Click to expand...</a>
                        </div>
                    </div>
                    <div id="project3" class="card">
                        <div class="cardImgParent">
                            <img src="res/label-maker.png" alt="LabelMaker UI">
                        </div>
                        <div>
                            <h2>Med. Recall Classifier</h2>
                            <h4>2019</h4>
                            <div class="tagbox tag4">
                                <p>ML</p>
                                <p>NLP</p>
                                <p>UI Design</p>
                                <p>Medical</p>
                                <p>Research</p>
                            </div>
                            <a id="project3Btn" class="button">Click to expand...</a>
                        </div>
                    </div>
                    <div id="project2" class="card">
                        <div class="cardImgParent">
                            <img src="res/tage-comp.png" alt="TAGE Branch Predictor Schematic">
                        </div>
                        <div>
                            <h2>TAGE Branch Predictor</h2>
                            <h4>2019</h4>
                            <div class="tagbox tag4">
                                <p>FPGA</p>
                                <p>Benchmarking</p>
                                <p>Research</p>
                                <p>Branch Prediction</p>
                            </div>
                            <a id="project2Btn" class="button">Click to expand...</a>
                        </div>
                    </div>
                    <div id="project1" class="card">
                        <div class="cardImgParent">
                            <img src="res/uvfit.png" alt="UV Fit Breadboard">
                        </div>
                        <div>
                            <h2>UV Fit</h2>
                            <h4>2018</h4>
                            <div class="tagbox tag4">
                                <p>Embedded Systems</p>
                                <p>Arduino</p>
                                <p>Wi-Fi</p>
                                <p>GPS</p>
                                <p>Website</p>
                            </div>
                            <a id="project1Btn" class="button">Click to expand...</a>
                        </div>
                    </div>
                    <div id="project0" class="card">
                        <div class="cardImgParent">
                            <img src="res/MIPS-pipeline-white.jpg" alt="5 Stage MIPS Pipeline">
                        </div>
                        <div>
                            <h2>5-Stage Processor</h2>
                            <h4>2017</h4>
                            <div class="tagbox tag4">
                                <p>FPGA</p>
                                <p>Processor Design</p>
                                <p>32bit MIPS</p>
                                <p>Multi-Staged</p>
                            </div>
                            <a id="project0Btn" class="button">Click to expand...</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div id="publicationsIndex" class="index">
            <div id="publications">
                <h1>Publications</h1>
                <div class="cardbox">
                    <div id="pub1" class="card">
                        <div class="cardImgParent">
                            <img src="res/lrec-tool.PNG" alt="Tool from LREC paper">
                        </div>
                        <div>
                            <h2>WorldTree V2: A Corpus of Science-Domain Structured Explanations and Inference Patterns supporting Multi-Hop Inference</h2>
                            <h4 style="font-style: italic;">LREC (2020) Xie and Thiem et al.</h4>
                            <div class="tagbox tag4">
                                <p>AI Research</p>
                                <p>NLP</p>
                                <p>UI Design</p>
                                <p>Big Data</p>
                                <p>Symbolic AI</p>
                            </div>
                            <a id="pub1Btn" class="button">Click to expand...</a>
                        </div>
                    </div>
                    <div id="pub0" class="card">
                        <div class="cardImgParent">
                            <img src="res/coin-megagraph.PNG" alt="Megagraph from COIN paper">
                        </div>
                        <div>
                            <h2>Extracting Common Inference Patterns from Semi-Structured Explanations</h2>
                            <h4 style="font-style: italic;">COIN EMNLP (2019) Thiem and Jansen</h4>
                            <div class="tagbox tag4">
                                <p>AI Research</p>
                                <p>NLP</p>
                                <p>UI Design</p>
                                <p>Invited To Speak</p>
                                <p>Symbolic AI</p>
                            </div>
                            <a id="pub0Btn" class="button">Click to expand...</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div id="project7Modal" class="modal hideModal">
        <div class="modal-content">
            <div class="modalTitleDiv">
                <h2>GLOCR</h2>
                <span id="project7BtnClose" class="modalCloseBtn">&times;</span>
            </div>
            <div class="modalMainDiv">
                <p>
                    This project will be building some of the necessary image analysis foundations to interpret and 
                    transmit grocery lists from a board to your phone. These foundations include the following operations 
                    on hand-written phrases: character segmentation, word/phrase segmentation, and character recognition.
                    Project can be accessed from this repository:<a href="https://github.com/SeaBass917/glocr" class="button"><i class="fab fa-github"></i>github</a>
                </p>
                <h3>Phase I (Word Segmentation)</h3>
                <p>
                    Using the “documents” portion of the IAM database (see Figure 1) an algorithm will be constructed that takes 
                    in a handwritten document and outputs the sentences and words as image files. Word segmentation is the critical 
                    part here, but for analysis purposes it would be productive to output the line segmentation step. There will also 
                    be some pre-processing involved including but not limited to: isolating the written text from the full document and 
                    noise reduction.
                </p>
                <center><img src="res/wordseg.png" alt="Segmented Words" style="width: 50%;"></center>
                <h3>Phase II (Character Segmentation) (Current Phase)</h3>
                <p>
                    The goal of this phase is to segment handwritten words into its character components. This will be tested on the 
                    “words” subsection of the IAM database (see Figure 3) and the resulting images from Phase I. Once provided an image 
                    of a word this algorithm will produce an ordered list of images for each of the characters in the word.
                </p>
                <h3>Phase III (Character Recognition)</h3>
                <p>
                    Character recognition is often done using pretrained and heavy deep neural nets. Such nets are compute intensive 
                    and would not fit the scope of this project, since ideally this would be run on an embedded device. For that reason 
                    this phase will involved a simple algorithm. This would be trained on EMNIST dataset or a derivative of this dataset.
                </p>
            </div>
            <div class="modalFooterDiv">
            </div>
        </div>
    </div>
    <div id="project6Modal" class="modal hideModal">
        <div class="modal-content">
            <div class="modalTitleDiv">
                <h2>Syncronicity: Pattern Authoring Tool</h2>
                <span id="project6BtnClose" class="modalCloseBtn">&times;</span>
            </div>
            <div class="modalMainDiv">
                <p>
                    The goal of this work was to generate a dataset that could train a model to 
                    generate human readable explanations to elementary science questions. 
                    This approach would use symbolic reasoning rather than the traditional 
                    statistical models (e.g. BERT). 
                    This project was sponsored by the lab of<a href="http://cognitiveai.org/" class="button">Peter Jansen</a>.
                </p>
                <p>
                    The idea here being to represent the knowledge and inference through the knowledge in the form of patterns.
                    These patterns could then be combined and culled by a model to form rich explanations that lay out a 
                    tracable path from the question to the answer.
                </p>
                <center><img src="res/coin-megagraph.PNG" alt="MEGAGRAPH!" style="width:70%;"></center>
                <p>
                    This work began with some intial experiments on how to extract the inference patterns from a corpus of thousands 
                    of explanations. We experimented with a top down approach that connected the knowledge based on a simple lexical 
                    overlap heuristic, on a subset of the full explanation corpus. 
                    This created a graph, where the nodes represented a set of facts, and the edges were the lexical constraints on 
                    the facts in their connected nodes. 
                    An expert in knowledge representation then went in, merged the nodes and trimmed edges, creating a still large, 
                    but much more legible graph of knowledge and inference.
                </p>
                <p>
                    I presented the results in Hong Kong in the COIN workshop at EMNLP. This methodology produced 67 patterns from 
                    knowledge graph. The patterns were high quality, but this method was not scalable. This inspired us to instead
                    use a bottum up approach.
                </p>
                <p>
                    The new approach involved automatically generating 100s of small low quality patterns and letting a trained 
                    annotator build the patterns up from there. This required much more work to be put into the annotation interface,
                    but resulted in a much larger yeild of 344 patterns. We no longer required a domain expert to annotate data, 
                    and the annotation could become more fine grained.
                </p>
                <center><img src="res/lrec-tool.PNG" alt="LREC Tool" style="width:70%;"></center>
            </div>
            <div class="modalFooterDiv">
                
            </div>
        </div>
    </div>
    <div id="project5Modal" class="modal hideModal">
        <div class="modal-content">
            <div class="modalTitleDiv">
                <h2>Pacman AI (Berkeley Open Source)</h2>
                <span id="project5BtnClose" class="modalCloseBtn">&times;</span>
            </div>
            <div class="modalMainDiv">
                <p>
                    This project was a semester long deep dive into traditional 
                    Artifical Intelligence models in the domain of Berkeleys open 
                    source pacman game. 
                </p>
                <p>
                    The project began with classic search algorithms such as BFS, DFS, A*, and greedy search.
                </p>
                <div style="display: flex; justify-content: space-evenly;">
                    <img src="res/pacman-maze.png" alt="Clever Pacman AI is never lost." style="width: 30%;">
                    <img src="res/pacman.png" alt="Pacman munching on some ghosts." style="width:52%;">
                </div>
                <p>
                    After search algorithms we designed agents and tuned our evaluation functions for the pacman character. 
                    Agents such as: 
                </p>
                <ul>
                    <li>Reflex Agent</li>
                    <li>Minimax(with alpha-beta pruning)</li>
                    <li>Expectimax</li>
                </ul>
                <p>
                    After traditional agents we moved on to reinforcement learning. 
                    This involved designing a <b>Q-learning</b> agent that learned to play pacman very reliably.
                </p>
                <p>
                    The last segment of the project involved handicapping pacman and having the agent hunt down ghosts blind.
                    The agent recieved auditory information from the ghosts and reasoned based on the amplitude where the ghosts were.
                    The ghosts had multiple agents that needed more complex models for optimum play as the ghost went from 
                    random movement, to intentional dispersal.
                </p>
            </div>
            <div class="modalFooterDiv">
                
            </div>
        </div>
    </div>
    <div id="project4Modal" class="modal hideModal">
        <div class="modal-content">
            <div class="modalTitleDiv">
                <h2>GPU Powered Signal Demodulation</h2>
                <span id="project4BtnClose" class="modalCloseBtn">&times;</span>
            </div>
            <div class="modalMainDiv">
                <img src="res/designday-Poster.png" alt="GPU Demod Team poster from Design Day 2019 UofA." style="width: 100%;">
                <p>
                    For my senior capstone project I worked with General Dynamics and a team of 4 other engineers to design a demodulation unit
                    that ran on a GPU. The goal being to compare the efficiency of the GPU implementation vs traditional ASIC designs.
                </p>
            </div>
            <div class="modalFooterDiv">
                
            </div>
        </div>
    </div>
    <div id="project3Modal" class="modal hideModal">
        <div class="modal-content">
            <div class="modalTitleDiv">
                <h2>Medical Device Recall Classification</h2>
                <span id="project3BtnClose" class="modalCloseBtn">&times;</span>
            </div>
            <div class="modalMainDiv">
                <p>
                    This work sought to explore novel methods of classifying hardware, software,
                    and security threats in device recall information. Previous work utilized 
                    key-word search based approaches, which worked well for hardware and software
                    classification, but was not as effective when trying to classify security threats.
                    Using a more complex language model like a weighted dictionary showed anincrease in 
                    classification accuracy across all three classes.
                </p>
                <p>
                    The data provided for the project was raw tabular data from the FDA. As such, in order to any sort of 
                    classification the data first needed to be annotated.
                    In order to expidite this process I designed an UI using python's Tkinter library that allowed me to 
                    quickly annotate a subset (1000 of 10440) of the samples.
                </p>
                <center><img src="res/label-maker.png" alt="Annotation tool used in medical device recall classification project." style="width: 50%;"></center>
                <p>
                    Notable features of the classifier
                </p>
                <ul>
                    <li>Counter for number of samples annotated in the session.</li>
                    <li>Live classification of the given sample from the current model.</li>
                    <li>
                        Options to retrive a sample:
                        <ul>
                            <li>At random</li>
                            <li>With a high confidence from the classifier</li>
                            <li>With a low confidence from the classifier</li>
                        </ul>
                    </li>
                    <li>Searching for samples with a given keyword.</li>
                </ul>
                <p>
                    8-fold accuracy of the classifier when compared to tradition grep methods used in previous work:
                </p>
                <table style="border: 1px solid white;">
                    <th>
                        <td style="font-weight: bold; text-align: right; border-right: 1px solid white; border-bottom: 1px solid white;">Class</td> <td style="font-weight: bold; border-bottom: 1px solid white;">Weighted Dictionary Accuracy</td> <td style="font-weight: bold; border-bottom: 1px solid white; border-left: 1px solid white;">Key-Word Accuracy</td>
                    </th>
                    <tr>
                        <td></td><td style="text-align: right; border-right: 1px solid white;">Security</td> <td style="text-align: center;">97.9%</td> <td style="text-align: center;">47.6%</td>
                    </tr>
                    <tr>
                        <td></td><td style="text-align: right; border-right: 1px solid white;">Hardware</td> <td style="text-align: center;">98.4%</td> <td style="text-align: center;">87.4%</td>
                    </tr>
                    <tr>
                        <td></td><td style="text-align: right; border-right: 1px solid white;">Software</td> <td style="text-align: center;">99.1%</td> <td style="text-align: center;">71.8%</td>
                    </tr>
                </table>
            </div>
            <div class="modalFooterDiv">
                
            </div>
        </div>
    </div>
    <div id="project2Modal" class="modal hideModal">
        <div class="modal-content">
            <div class="modalTitleDiv">
                <h2>TAGE Branch Predictor</h2>
                <span id="project2BtnClose" class="modalCloseBtn">&times;</span>
            </div>
            <div class="modalMainDiv">
                <center><img src="res/tage-comp.png" alt="TAGE design schematic" style="width: 50%;"></center>
                <p>
                    This research sought to compare the performance of a low-budget(2KB) perceptron-based branch predictor to the state of the art
                    TAGE branch predictor at a similar budget. The TAGE in this work was implemented and benchmarked on an FPGA, running Seznec’s L-TAGE 
                    design on the Simple-Scalar benchmarks in Verilog.
                </p>
                <center><img src="res/tage-internals.png" alt="TAGE internal design schematic, hand-drawn" style="width: 50%;"></center>
                <p>
                    The source code was not openly available, so the paper had to be studied and the TAGE engineered from the description.
                </p>
                <p>
                    The basic idea behind a TAGE design involves hashing into tables of counters using the branch history and current instruction counter 
                    in the hashing function.
                    The counters keep track of the branching patterns, while the hashing ensures that the counter we read is associcated with the 
                    current state. The TAGE uses multiple tables with a geometrically increasing history length. Each table is read, but only the 
                    longest history length table with a match on the current history/instruction will be read.
                </p>
            </div>
            <div class="modalFooterDiv">
                
            </div>
        </div>
    </div>
    <div id="project1Modal" class="modal hideModal">
        <div class="modal-content">
            <div class="modalTitleDiv">
                <h2>UV Fit</h2>
                <span id="project1BtnClose" class="modalCloseBtn">&times;</span>
            </div>
            <div class="modalMainDiv">

            </div>
            <div class="modalFooterDiv">
                
            </div>
        </div>
    </div>
    <div id="project0Modal" class="modal hideModal">
        <div class="modal-content">
            <div class="modalTitleDiv">
                <h2>5-Stage Pipelined 32bit MIPS Processor</h2>
                <span id="project0BtnClose" class="modalCloseBtn">&times;</span>
            </div>
            <div class="modalMainDiv">

            </div>
            <div class="modalFooterDiv">
                
            </div>
        </div>
    </div>
    <div id="pub1Modal" class="modal hideModal">
        <div class="modal-content">
            <div class="modalTitleDiv">
                <h2>WorldTree V2: A Corpus of Science-Domain Structured Explanations and Inference Patterns supporting Multi-Hop Inference</h2>
                <span id="pub1BtnClose" class="modalCloseBtn">&times;</span>
            </div>
            <div class="modalMainDiv">
                <h4 style="font-style: italic;">LREC (2020) Xie and Thiem et al.</h4>
                <img src="res/lrec-tool.PNG" alt="Tool from LREC paper" style="width: 100%;">
                <p>
                    Explainable question answering for complex questions often requires combining large numbers 
                    of facts to answer a question while providing a human-readable explanation for the answer, 
                    a process known as multi-hop inference. Standardized science questions require combining an 
                    average of 6 facts, and as many as 16 facts, in order to answer and explain, but most 
                    existing datasets for multi-hop reasoning focus on combining only two facts, significantly 
                    limiting the ability of multi-hop inference algorithms to learn to generate large inferences. 
                    In this work we present the second iteration of the WorldTree project, a corpus of 5,114 
                    standardized science exam questions paired with large detailed multi-fact explanations that 
                    combine core scientific knowledge and world knowledge. Each explanation is represented as a 
                    lexically-connected “explanation graph” that combines an average of 6 facts drawn from a 
                    semi-structured knowledge base of 9,216 facts across 66 tables. We use this explanation 
                    corpus to author a set of 344 high-level science domain inference patterns similar to semantic 
                    frames supporting multi-hop inference. Together, these resources provide training data and 
                    instrumentation for developing many-fact multi-hop inference models for question answering.
                </p>
            </div>
            <div class="modalFooterDiv">
                <a class="button" href="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.671.pdf" target="_blank">Full Paper</a>
            </div>
        </div>
    </div>
    <div id="pub0Modal" class="modal hideModal">
        <div class="modal-content">
            <div class="modalTitleDiv">
                <h2>Extracting Common Inference Patterns from Semi-Structured Explanations</h2>
                <span id="pub0BtnClose" class="modalCloseBtn">&times;</span>
            </div>
            <div class="modalMainDiv">
                <h4 style="font-style: italic;">COIN EMNLP (2019) Thiem and Jansen</h4>
                <img src="res/coin-megagraph.PNG" alt="Tool from LREC paper" style="width: 100%;">
                <p>
                    Complex questions often require combining multiple facts to correctly answer, 
                    particularly when generating detailed explanations for why those answers are correct. 
                    Combining multiple facts to answer questions is often modeled as a “multi-hop” graph traversal 
                    problem, where a given solver must find a series of interconnected facts in a knowledge graph that, 
                    taken together, answer the question and explain the reasoning behind that answer. Multi-hop inference 
                    currently suffers from semantic drift, or the tendency for chains of reasoning to “drift”’ to unrelated 
                    topics, and this semantic drift greatly limits the number of facts that can be combined in both free text 
                    or knowledge base inference. In this work we present our effort to mitigate semantic drift by extracting 
                    large high-confidence multi-hop inference patterns, generated by abstracting large-scale explanatory structure 
                    from a corpus of detailed explanations. We represent these inference patterns as sets of generalized constraints 
                    over sentences represented as rows in a knowledge base of semi-structured tables. We present a prototype tool for 
                    identifying common inference patterns from corpora of semi-structured explanations, and use it to successfully 
                    extract 67 inference patterns from a “matter” subset of standardized elementary science exam questions that span 
                    scientific and world knowledge.
                </p>
            </div>
            <div class="modalFooterDiv">
                <a class="button" href="https://www.aclweb.org/anthology/D19-6006.pdf" target="_blank">Full Paper</a>
            </div>
        </div>
    </div>
</body>

</html>